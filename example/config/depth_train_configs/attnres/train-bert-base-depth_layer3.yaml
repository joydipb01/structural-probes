dataset:
  observation_fieldnames:
     - index
     - sentence
     - lemma_sentence
     - upos_sentence
     - xpos_sentence
     - morph
     - head_indices
     - governance_relations
     - secondary_relations
     - extra_info
     - embeddings
  corpus:
    root: example/data/en_ewt-ud-sample/
    train_path: en_ewt-ud-train.conllu
    dev_path: en_ewt-ud-dev.conllu
    test_path: en_ewt-ud-test.conllu
  embeddings:
    type: token #{token,subword}
    root: example/data/en_ewt-ud-sample/ 
    train_path: en_ewt-ud-train.norm_bert_res_n.hdf5
    dev_path: en_ewt-ud-dev.norm_bert_res_n.hdf5
    test_path: en_ewt-ud-test.norm_bert_res_n.hdf5
  batch_size: 40

model:
  hidden_dim: 768 # ELMo hidden dim
  #embedding_dim: 1024 # ELMo word embedding dim
  model_type: BERT-disk # BERT-disk, ELMo-disk,
  tokenizer:
    type: word
    vocab_path: example/vocab.vocab
  use_disk: True
  model_layer: 2 # BERT-base: {1,...,12}; ELMo: {1,2,3}

probe:
  task_signature: word # word, word_pair
  task_name: parse-depth
  maximum_rank: 32
  psd_parameters: True
  diagonal: False
  params_path: norm-attnres-bertbase-depth-probe_layer3.params
probe_training:
  epochs: 30
  loss: L1

reporting:
  root: example/bert-base-depth-params
  observation_paths:
    train_path: train.observations
    dev_path: dev.observations
    test_path: test.observations
  prediction_paths:
    train_path: train.predictions
    dev_path: dev.predictions
    test_path: test.predictions
  reporting_methods:
    - spearmanr
      #- image_examples
    - uuas

device: cpu
